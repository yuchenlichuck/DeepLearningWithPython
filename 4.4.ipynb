{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "original_model = models.Sequential()\n",
    "original_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "original_model.add(layers.Dense(16, activation='relu'))\n",
    "original_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "original_model.compile(optimizer='rmsprop',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_model = models.Sequential()\n",
    "smaller_model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "smaller_model.add(layers.Dense(4, activation='relu'))\n",
    "smaller_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "smaller_model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dense 标准的一维全连接层\n",
    "\n",
    "keras.layers.Dense(units, \n",
    "\t\t\t\t  activation=None, \n",
    "\t\t\t\t  use_bias=True, \n",
    "\t\t\t\t  kernel_initializer='glorot_uniform', \n",
    "\t\t\t\t  bias_initializer='zeros', \n",
    "\t\t\t\t  kernel_regularizer=None, \n",
    "\t\t\t\t  bias_regularizer=None, \n",
    "\t\t\t    activity_regularizer=None, \n",
    "\t\t\t\t  kernel_constraint=None, \n",
    "            bias_constraint=None)\n",
    "以下给出Dense方法的使用示例：\n",
    "\n",
    "keras.layers.Dense(512, activation= 'sigmoid', input_dim= 2, use_bias= True)\n",
    "这里定义了一个有512个节点，使用sigmoid激活函数的神经层，注意定义第一层的时候需要制定数据输入的形状，即input_dim，这样才能让数据正常喂进网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 9s 374us/step - loss: 0.4440 - acc: 0.8251 - val_loss: 0.3286 - val_acc: 0.8835\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 11s 429us/step - loss: 0.2573 - acc: 0.9078 - val_loss: 0.2864 - val_acc: 0.8882\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 7s 296us/step - loss: 0.1991 - acc: 0.9294 - val_loss: 0.2822 - val_acc: 0.8891\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 7s 272us/step - loss: 0.1666 - acc: 0.9413 - val_loss: 0.2940 - val_acc: 0.8847\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 12s 476us/step - loss: 0.1434 - acc: 0.9498 - val_loss: 0.3115 - val_acc: 0.8807\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 18s 703us/step - loss: 0.1257 - acc: 0.9556 - val_loss: 0.3475 - val_acc: 0.8721\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 15s 617us/step - loss: 0.1110 - acc: 0.9618 - val_loss: 0.3584 - val_acc: 0.8734\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 5s 219us/step - loss: 0.0978 - acc: 0.9669 - val_loss: 0.3955 - val_acc: 0.8660\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 237us/step - loss: 0.0841 - acc: 0.9723 - val_loss: 0.4241 - val_acc: 0.8642\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 240us/step - loss: 0.0756 - acc: 0.9758 - val_loss: 0.4975 - val_acc: 0.8523\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.0686 - acc: 0.9778 - val_loss: 0.4866 - val_acc: 0.8586\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 0.0565 - acc: 0.9830 - val_loss: 0.5184 - val_acc: 0.8558\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 0.0513 - acc: 0.9842 - val_loss: 0.5341 - val_acc: 0.8575\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 223us/step - loss: 0.0426 - acc: 0.9879 - val_loss: 0.6150 - val_acc: 0.8490\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 249us/step - loss: 0.0369 - acc: 0.9894 - val_loss: 0.6069 - val_acc: 0.8548\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 250us/step - loss: 0.0309 - acc: 0.9909 - val_loss: 0.6407 - val_acc: 0.8535\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 251us/step - loss: 0.0263 - acc: 0.9930 - val_loss: 0.6874 - val_acc: 0.8523\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.0206 - acc: 0.9953 - val_loss: 0.7290 - val_acc: 0.8505\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 5s 219us/step - loss: 0.0188 - acc: 0.9954 - val_loss: 0.7546 - val_acc: 0.8508\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.0152 - acc: 0.9966 - val_loss: 0.9771 - val_acc: 0.8322\n"
     ]
    }
   ],
   "source": [
    "original_hist=original_model.fit(x_train,y_train,epochs=20,batch_size=512,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 13s 511us/step - loss: 0.5804 - acc: 0.7027 - val_loss: 0.5309 - val_acc: 0.7558\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 7s 279us/step - loss: 0.4843 - acc: 0.8455 - val_loss: 0.4876 - val_acc: 0.8280\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 5s 208us/step - loss: 0.4389 - acc: 0.8920 - val_loss: 0.4663 - val_acc: 0.8497\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 5s 199us/step - loss: 0.4077 - acc: 0.9154 - val_loss: 0.4526 - val_acc: 0.8663\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 5s 197us/step - loss: 0.3832 - acc: 0.9304 - val_loss: 0.4514 - val_acc: 0.8621\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 5s 197us/step - loss: 0.3620 - acc: 0.9414 - val_loss: 0.4425 - val_acc: 0.8725\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 5s 200us/step - loss: 0.3425 - acc: 0.9517 - val_loss: 0.4495 - val_acc: 0.8668\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 5s 199us/step - loss: 0.3261 - acc: 0.9560 - val_loss: 0.4538 - val_acc: 0.8662\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 5s 198us/step - loss: 0.3101 - acc: 0.9616 - val_loss: 0.4734 - val_acc: 0.8606\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 5s 200us/step - loss: 0.2959 - acc: 0.9652 - val_loss: 0.4692 - val_acc: 0.8630\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 5s 200us/step - loss: 0.2815 - acc: 0.9691 - val_loss: 0.4937 - val_acc: 0.8582\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 226us/step - loss: 0.2685 - acc: 0.9722 - val_loss: 0.4850 - val_acc: 0.8623\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.2567 - acc: 0.9744 - val_loss: 0.5121 - val_acc: 0.8581\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 5s 202us/step - loss: 0.2453 - acc: 0.9762 - val_loss: 0.5452 - val_acc: 0.8548\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 5s 210us/step - loss: 0.2337 - acc: 0.9779 - val_loss: 0.5129 - val_acc: 0.8594\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.2237 - acc: 0.9800 - val_loss: 0.5389 - val_acc: 0.8572\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.2146 - acc: 0.9813 - val_loss: 0.5776 - val_acc: 0.8550\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 5s 209us/step - loss: 0.2052 - acc: 0.9823 - val_loss: 0.5864 - val_acc: 0.8547\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.1967 - acc: 0.9827 - val_loss: 0.6583 - val_acc: 0.8496\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 6s 233us/step - loss: 0.1892 - acc: 0.9834 - val_loss: 0.6602 - val_acc: 0.8499\n"
     ]
    }
   ],
   "source": [
    "smaller_model_hist = smaller_model.fit(x_train, y_train,\n",
    "                                       epochs=20,\n",
    "                                       batch_size=512,\n",
    "                                       validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, 21)\n",
    "original_val_loss = original_hist.history['val_loss']\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, smaller_model_val_loss, 'bo', label='Smaller model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the smaller network starts overfitting later than the reference one (after 6 epochs rather than 4) and its performance degrades much more slowly once it starts overfitting.\n",
    "\n",
    "Now, for kicks, let's add to this benchmark a network that has much more capacity, far more than the problem would warrant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding weight regularization\n",
    "You may be familiar with Occam's Razor principle: given two explanations for something, the explanation most likely to be correct is the \"simplest\" one, the one that makes the least amount of assumptions. This also applies to the models learned by neural networks: given some training data and a network architecture, there are multiple sets of weights values (multiple models) that could explain the data, and simpler models are less likely to overfit than complex ones.\n",
    "\n",
    "A \"simple model\" in this context is a model where the distribution of parameter values has less entropy (or a model with fewer parameters altogether, as we saw in the section above). Thus a common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to only take small values, which makes the distribution of weight values more \"regular\". This is called \"weight regularization\", and it is done by adding to the loss function of the network a cost associated with having large weights. This cost comes in two flavors:\n",
    "\n",
    "L1 regularization, where the cost added is proportional to the absolute value of the weights coefficients (i.e. to what is called the \"L1 norm\" of the weights).\n",
    "L2 regularization, where the cost added is proportional to the square of the value of the weights coefficients (i.e. to what is called the \"L2 norm\" of the weights). L2 regularization is also called weight decay in the context of neural networks. Don't let the different name confuse you: weight decay is mathematically the exact same as L2 regularization.\n",
    "In Keras, weight regularization is added by passing weight regularizer instances to layers as keyword arguments. Let's add L2 weight regularization to our movie review classification network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "l2_model=models.Sequential()\n",
    "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),activation='relu',input_shape=(10000,)))\n",
    "l2_model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "l2_model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 7s 268us/step - loss: 0.5041 - acc: 0.8084 - val_loss: 0.3782 - val_acc: 0.8838\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.3131 - acc: 0.9066 - val_loss: 0.3327 - val_acc: 0.8897\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.2665 - acc: 0.9220 - val_loss: 0.3681 - val_acc: 0.8700\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 223us/step - loss: 0.2481 - acc: 0.9288 - val_loss: 0.3386 - val_acc: 0.8863\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 5s 217us/step - loss: 0.2354 - acc: 0.9354 - val_loss: 0.3803 - val_acc: 0.8694\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.2248 - acc: 0.9394 - val_loss: 0.3589 - val_acc: 0.8797\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.2174 - acc: 0.9428 - val_loss: 0.3788 - val_acc: 0.8726\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 5s 218us/step - loss: 0.2167 - acc: 0.9440 - val_loss: 0.3738 - val_acc: 0.8777\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.2101 - acc: 0.9440 - val_loss: 0.4003 - val_acc: 0.8678\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 0.2039 - acc: 0.9482 - val_loss: 0.4106 - val_acc: 0.8680\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.2032 - acc: 0.9463 - val_loss: 0.3991 - val_acc: 0.8699\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.1956 - acc: 0.9499 - val_loss: 0.4163 - val_acc: 0.8664\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 5s 208us/step - loss: 0.1929 - acc: 0.9531 - val_loss: 0.4179 - val_acc: 0.8704\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.1883 - acc: 0.9544 - val_loss: 0.5290 - val_acc: 0.8337\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.1881 - acc: 0.9542 - val_loss: 0.4820 - val_acc: 0.8505\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 5s 203us/step - loss: 0.1803 - acc: 0.9580 - val_loss: 0.4806 - val_acc: 0.8504\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 0.1810 - acc: 0.9573 - val_loss: 0.4201 - val_acc: 0.8696\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 5s 204us/step - loss: 0.1788 - acc: 0.9575 - val_loss: 0.4254 - val_acc: 0.8664\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 5s 207us/step - loss: 0.1741 - acc: 0.9598 - val_loss: 0.4334 - val_acc: 0.8655\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 5s 205us/step - loss: 0.1706 - acc: 0.9614 - val_loss: 0.5019 - val_acc: 0.8475\n"
     ]
    }
   ],
   "source": [
    "l2_model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['acc'])\n",
    "l2_model_hist = l2_model.fit(x_train, y_train,\n",
    "                             epochs=20,\n",
    "                             batch_size=512,\n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuYFPWV//H3YYQginc0KJdBfmi4DSADaC4q3lCjoOKNsNkMJrJqUNSs0YgJo/m5UX+JrreYoBJ0ZUXFqCRhozEoPLoky6BcZbnoMjqB1RFFxJHI5fz+qJqmGXqme6a7unqmP6/n6We6qr9ddbpo6nR9v1WnzN0REREBaBd3ACIiUjiUFEREJEFJQUREEpQUREQkQUlBREQSlBRERCRBSUFERBKUFEREJEFJQUREEvaJasFmNh04B/jA3QekeN2Ae4GzgTqgwt3fSLfcww47zEtLS3McrYhI27Z48eIP3b1LunaRJQVgBvAA8Hgjr58F9AkfI4CHwr9NKi0tpaqqKkchiogUBzOrzqRdZN1H7r4A+KiJJmOAxz3wF+AgM+saVTwiIpJenGMKRwHvJU3XhPNERCQmcSYFSzEvZclWM5toZlVmVlVbWxtxWCIixSvKMYV0aoDuSdPdgA2pGrr7NGAaQHl5+V6JY/v27dTU1LBt27Yo4pQ2qGPHjnTr1o327dvHHYpIQYkzKcwBJpnZLIIB5k/cfWNLFlRTU0Pnzp0pLS0lOKlJpHHuzqZNm6ipqaFXr15xhyNSUCLrPjKzJ4GFwLFmVmNm3zWzK8zsirDJXOAdYB3wMHBVS9e1bds2Dj30UCUEyYiZceihh+rIUlqdysro1xHZkYK7j0vzugPfz9X6lBCkOfR9kdbo1lujTwy6ollERBKUFHKkpqaGMWPG0KdPH3r37s3kyZP54osvUrbdsGEDF154Ydplnn322WzevLlF8VRWVvLzn/+8Re/N1IwZM5g0aVLWbUSkcZWVYBY8YPfzqI4Yijop5GqjujsXXHAB5513HmvXrmXNmjVs3bqVKVOm7NV2x44dHHnkkcyePTvtcufOnctBBx2UmyBFpFWqrAT34AG7nyspRODWW3OznHnz5tGxY0cmTJgAQElJCffccw/Tp0+nrq6OGTNmcNFFF3HuuedyxhlnsH79egYMCMpB1dXVcfHFF1NWVsYll1zCiBEjEmU8SktL+fDDD1m/fj19+/bl8ssvp3///pxxxhl8/vnnADz88MMMGzaMQYMGMXbsWOrq6pqMtaKigiuvvJKRI0dy9NFHM3/+fC677DL69u1LRUVFot2TTz7JwIEDGTBgADfeeGNi/m9+8xuOOeYYTjrpJF5//fXE/NraWsaOHcuwYcMYNmzYHq+JSOtR1EkhV1auXMnQoUP3mHfAAQfQo0cP1q1bB8DChQt57LHHmDdv3h7tfvnLX3LwwQezbNkyfvzjH7N48eKU61i7di3f//73WblyJQcddBDPPvssABdccAGLFi1i6dKl9O3bl0cffTRtvB9//DHz5s3jnnvu4dxzz+W6665j5cqVLF++nCVLlrBhwwZuvPFG5s2bx5IlS1i0aBHPP/88GzduZOrUqbz++uv86U9/4q233kosc/LkyVx33XUsWrSIZ599lu9973vN2oYikt7UqdGvI87rFGJRWbnnEUJ9P93UqS0/HHP3lGezJM8//fTTOeSQQ/Zq89prrzF58mQABgwYQFlZWcp19OrVi8GDBwMwdOhQ1q9fD8CKFSu45ZZb2Lx5M1u3bmXUqFFp4z333HMxMwYOHMgRRxzBwIEDAejfvz/r16+nurqak08+mS5dgoKK48ePZ8GCBQB7zL/kkktYs2YNAC+//PIeSWLLli18+umnaWMRkcy16lNSC1Vl5e4Na7a7ny4b/fv3T/xyr7dlyxbee+89evfuzeLFi9lvv/1SvtczDOBLX/pS4nlJSUmi+6iiooLnn3+eQYMGMWPGDF599dWMl9WuXbs9ltuuXTt27NjBPvs0/rVo7FTOXbt2sXDhQvbdd99MPo6IFCh1H+XAqaeeSl1dHY8/HlQJ37lzJz/4wQ+oqKigU6dOTb7361//Ok8//TQAb731FsuXL2/Wuj/99FO6du3K9u3bmTlzZss+QAMjRoxg/vz5fPjhh+zcuZMnn3ySk046iREjRvDqq6+yadMmtm/fzjPPPJN4zxlnnMEDDzyQmF6yZElOYhGR/CrqpJCr/jkz47nnnuOZZ56hT58+HHPMMXTs2JF/+Zd/Sfveq666itraWsrKyrjzzjspKyvjwAMPzHjdP/3pTxkxYgSnn346X/nKV7L5GAldu3blZz/7GSNHjmTQoEEcd9xxjBkzhq5du1JZWckJJ5zAaaedxnHHHZd4z3333UdVVRVlZWX069ePX/3qVzmJRUTyyzLtvigU5eXl3vAmO6tWraJv374xRZSdnTt3sn37djp27Mjbb7/Nqaeeypo1a+jQoUPcobV5rfl7I9JcZrbY3cvTtSu6MYVCU1dXx8iRI9m+fTvuzkMPPaSEICKxUVKIWefOnXV7UREpGEU9piAiIntSUhARkQQlBRERSVBSEBGRBCWFHNl///33mnf33XfTr18/ysrKOPXUU6murs57XC0poT1nzhzuuOOOrNd98sknRz6IXlFRkbbibCZtRCRQlElh5kwoLYV27YK/OboQeC9DhgyhqqqKZcuWceGFF/LDH/4w7Xt27NgRTTAZ2rFjB6NHj+amm26KNQ4RiUfRJYWZM2HiRKiuDuoeVVcH01EkhpEjRybKXBx//PHU1NSkbFdRUcH111/PyJEjufHGG/nss8+47LLLGDZsGEOGDOGFF14Ami6znXykMnv27D3KYNdrrMx2w/Un3xhn8ODBice+++7L/PnzG43v888/59JLL03EV1+fqaHS0lJuvvlmTjjhBMrLy3njjTcYNWoUvXv3TlwJ7e7ccMMNDBgwgIEDB/LUU08l5k+aNIl+/frxzW9+kw8++CCx3MWLF3PSSScxdOhQRo0axcaNGzP7hxKRhKK7TmHKFGh4y4G6umD++PHRrffRRx/lrLPOavT1NWvW8PLLL1NSUsLNN9/MKaecwvTp09m8eTPDhw/ntNNO46GHHkqU2V6xYkWiamqmLrjgAi6//HIAbrnlFh599FGuvvrqvdY/Y8aMxHvqaxj97ne/46677uKrX/0qU6dOTRnfr3/9azp16sSyZctYtmzZHmUwGurevTsLFy7kuuuuo6Kigtdff51t27bRv39/rrjiCn7729+yZMkSli5dyocffsiwYcM48cQTWbhwIatXr2b58uW8//779OvXj8suu4zt27dz9dVX88ILL9ClSxeeeuoppkyZwvTp05u1jUSKXaRJwczOBO4FSoBH3P2OBq/3BKYDXYCPgH9w99Q/p3Pk3XebNz8XnnjiCaqqqpg/f36jbS666CJKSkoAeOmll5gzZ05iLGDbtm28++67GZfZbkxTZbaT19/Q2rVrueGGG5g3bx7t27dvNL4FCxZwzTXXAFBWVtZkfKNHjwZg4MCBbN26lc6dO9O5c2c6duzI5s2bee211xg3bhwlJSUcccQRnHTSSSxatIgFCxYk5h955JGccsopAKxevZoVK1Zw+umnA0H5kK5duzZr+4hIhEnBzEqAB4HTgRpgkZnNcfe3kpr9HHjc3R8zs1OAnwHfjiomgB49gi6jVPOj8PLLL3P77bczf/78RJnqKVOm8Ic//AHY/Us8ubS2u/Pss89y7LHH7rGspupUJZe03rZtW8o2TZXZbqy092effcbFF1/Mww8/zJFHHtlkfA3jaEq68t2ZftZ67k7//v1ZuHBhRusXkdSiHFMYDqxz93fc/QtgFjCmQZt+wJ/D56+keD3nbr8dGlaz7tQpmJ9rb775Jv/0T//EnDlzOPzww5NiuJ0lS5Y0Wl561KhR3H///Ykd45tvvgk0XWb7iCOOYNWqVezatYvnnnsu5XJbUmZ7woQJTJgwgW984xtp4zvxxBMTy12xYgXLli3LaB2pnHjiiTz11FPs3LmT2tpaFixYwPDhwznxxBOZNWsWO3fuZOPGjbzyyisAHHvssdTW1iaSwvbt21m5cmWL1y9SrKLsPjoKeC9pugYY0aDNUmAsQRfT+UBnMzvU3TclNzKzicBEgB5Z/qSvHzeYMiXoMurRI0gI2Y4n1NXV0a1bt8T09ddfz9y5c9m6dSsXXXQREMQ+Z86ctMv68Y9/zLXXXktZWRnuTmlpKb///e+56qqr+M53vkNZWRlDhgzZo8z2HXfcwTnnnEP37t0ZMGAAW7du3Wu59WW2e/bsycCBA9PeGa26uprZs2ezZs2aRN/8I4880mh8V155JRMmTKCsrIzBgwczfPjwjLdfQ+effz4LFy5k0KBBmBl33XUXX/7ylzn//POZN28eAwcOTNwrGqBDhw7Mnj2ba665hk8++YQdO3Zw7bXX0r9//xbHIFKMIiudbWYXAaPc/Xvh9LeB4e5+dVKbI4EHgF7AAoIE0d/dP2lsuW2tdHZzqMx2bhXL90YECqN0dg3QPWm6G7AhuYG7bwAuADCz/YGxTSWEYqcy2yIStSiTwiKgj5n1Av4GXAp8K7mBmR0GfOTuu4AfEZyJJI1QmW0RiVpkA83uvgOYBLwIrAKedveVZnabmY0Om50MrDazNcARQIuHe1vbHeQkXvq+iKQW6XUK7j4XmNtg3k+Sns8Gsi5K07FjRzZt2sShhx6a8SmRUrzcnU2bNtGxY8e4QxEpOG3iiuZu3bpRU1NDbW1t3KFIK9GxY8c9zhYTkUCbSArt27enV69ecYchItLqFV1BPBERaZySgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEhCpEnBzM40s9Vmts7Mbkrxeg8ze8XM3jSzZWZ2dpTxiIhI0yJLCmZWAjwInAX0A8aZWb8GzW4Bnnb3IcClwC+jikdERNKL8khhOLDO3d9x9y+AWcCYBm0cOCB8fiCwIcJ4REQkjX0iXPZRwHtJ0zXAiAZtKoGXzOxqYD/gtAjjERGRNKI8UrAU87zB9Dhghrt3A84G/s3M9orJzCaaWZWZVdXW1kYQqoiIQLRJoQbonjTdjb27h74LPA3g7guBjsBhDRfk7tPcvdzdy7t06RJRuCIiEmVSWAT0MbNeZtaBYCB5ToM27wKnAphZX4KkoEMBEZGYRJYU3H0HMAl4EVhFcJbRSjO7zcxGh81+AFxuZkuBJ4EKd2/YxSQiInkS5UAz7j4XmNtg3k+Snr8FfC3KGEREJHO6ollERBKUFEREJEFJQUREEpQUREQkQUlBREQSlBRERPKksjLuCNJTUhARyZNbb407gvSUFEREJCFtUjCz/eqL1JnZMWY22szaRx+aiEjrV1kJZsEDdj8v1K4kS1dVwswWA98ADgb+AlQBde4+Pvrw9lZeXu5VVVVxrFpEJCtmEFchHzNb7O7l6dpl0n1k7l4HXADc7+7nE9xJTURE2piMkoKZnQCMB/4Qzou0ZpKISFs0dWrcEaSXSVK4FvgR8FxY5fRo4JVowxIRKTzZjgMU6jhCsrRjCns0Dgac93f3LdGF1DSNKYhIXOIcE8hWzsYUzOzfzewAM9sPeAtYbWY35CJIEREpLJl0H/ULjwzOI7g3Qg/g25FGJSJSIFrbKaXZyiQptA+vSzgPeMHdtwOt9ABKRKR5KiuDLqP6bqP658WcFH4NrAf2AxaYWU8gtjEFERGJTtpTS939PuC+pFnVZjYyupBERApTazilNFuZDDQfaGZ3m1lV+PgFwVFDWmZ2ppmtNrN1ZnZTitfvMbMl4WONmW1uwWcQEcmLttpllCyT7qPpwKfAxeFjC/CbdG8ysxLgQeAsgiugx5nZHldCu/t17j7Y3QcD9wO/bV74IiKSS5lcmdzb3ccmTd9qZksyeN9wYJ27vwNgZrOAMQSntaYyDiiCgzMRkcKVyZHC52b29foJM/sa8HkG7zsKeC9puiact5dw8LoXMC+D5YqISEQyOVK4EnjMzA4EDPgIqMjgfZZiXmOnsl4KzHb3nSkXZDYRmAjQo0ePDFYtIiItkfZIwd2XuPsgoAwY6O5D3H1pBsuuAbonTXcDNjTS9lLgySZimObu5e5e3qVLlwxWLSKyt2IYKM5Wo7WPzOz6pt7o7nc3uWCzfYA1wKnA34BFwLfcfWWDdscCLwK9PINCTKp9JCIt1ZprF2Ur09pHTXUfdc4mAHffYWaTCHb4JcD0sMrqbUCVu88Jm44DZmWSEEREJFrNqpJaCHSkICLNUVkJt9669/ypU4urOynTIwUlBREpGuo+ys3tOEVEpEgoKYhI0SiG2kXZSnudgpl9CRgLlCa3d/fbogtLRCT3imkMoaUyuXjtBeATYDHw92jDERGROGWSFLq5+5mRRyIiIrHLZEzhP81sYOSRiIhI7DI5Uvg6UGFm/0PQfWSAu3tZpJGJiEjeZZIUzoo8ChERKQiZFMSrBg4Czg0fB4XzRETySmcPRS+T23FOBmYCh4ePJ8zs6qgDExFpKFW5CsmtTLqPvguMcPfPAMzsTmAhwe0zRUSkDcnk7CMDkm9+s5PUN9AREcm5ysqgZpGFe5365+pKikYmRwq/Af5qZs+F0+cBj0YXkojIbpWVuxNAMRe0y5e0ScHd7zazVwlOTTVggru/GXVgIiKSf40mBTM7wN23mNkhwPrwUf/aIe7+UfThiYjspoJ20WtqTOHfw7+LgaqkR/20iBSZuPvx415/MdBNdkQkY+rTb71ydpMdM/tzJvNERKT1azQpmFnHcDzhMDM72MwOCR+lwJH5ClBE4pXLU0LV/VP4Gu0+Cq9kvpYgAfyN3dcmbAEedvcH0i7c7EzgXqAEeMTd70jR5mKgEnBgqbt/q6llqvtIJD7Zdh+p+yk+mXYfNXr2kbvfC9xrZle7e7OvXjazEuBB4HSgBlhkZnPc/a2kNn2AHwFfc/ePzezw5q5HRERyJ5OCePeb2QAzu9jM/rH+kcGyhwPr3P0dd/8CmAWMadDmcuBBd/84XNcHzf0AIpI/LTklVFckty6Z3KN5KnAy0A+YS1BK+zXg8TRvPQp4L2m6BhjRoM0x4TpeJ+hiqnT3P2YSuIjkX0vHEXRFcuuRSe2jC4FTgf919wnAIOBLGbwvVX2khl+HfYA+BElnHPCImR2014LMJppZlZlV1dbWZrBqERFpiUySwufuvgvYYWYHAB8AR2fwvhqge9J0N2BDijYvuPt2d/8fYDVBktiDu09z93J3L+/SpUsGqxaRQqQrkgtfJkmhKvz1/jDB1cxvAP+VwfsWAX3MrJeZdQAuBeY0aPM8MBLAzA4j6E56J8PYRaSV0ThC4cukIN5V4dNfmdkfgQPcfVkG79thZpOAFwnGC6a7+0ozuw2ocvc54WtnmNlbBCW5b3D3TS39MCIikp2mrlM4rqk3uvsbkUSUhq5TEBFpvqyvUwB+Ef7tCJQDSwkGj8uAvxKU0hYRkTak0TEFdx/p7iOBauC4cKB3KDAEWJevAEVEJH8yGWj+irsvr59w9xXA4OhCEhGRuGRyO85VZvYI8ATBdQb/AKyKNCoREYlFJklhAnAlMDmcXgA8FFlEIiISm0xOSd0G3BM+RESkDWvqHs1Pu/vFZracvctT4O5lkUYmIiJ519SRQn130Tn5CEREROLX1P0UNoZ/q/MXjoiIxKmp7qNPSdFtRHABm7v7AZFFJSIisWjq4rXO7n5AikdnJQSR1kkF6SSdTC5eA8DMDjezHvWPKIMSkWjcemvcEUihS5sUzGy0ma0F/geYD6wH/iPiuESkgMycCaWl0K5d8HfmzLgjkqhkcqTwU+B4YI279yK4C9vrkUYlIjmT7T2SZ86EiROhujq4lWZ1dTCtxNA2NVo6O9HArMrdy81sKTDE3XeZ2X+5+/D8hLgnlc4WabmW3CO5tDRIBA317Anr1+ciKsmHTEtnZ3KksNnM9icobzHTzO4FdmQboIg0XxwDxe++27z50rplkhTGAJ8D1wF/BN4Gzo0yKBFJLduB4pbcI7lHI6eVNDZfWrdGk4KZPWBmX3X3z9x9p7vvcPfH3P0+3TJTpHVqyZHG7bdDp057zuvUKZgvbU9TRwprgV+Y2Xozu9PMdA8FkRhkO1CcrfHjYdq0YAzBLPg7bVowX9qepi5eu9fdTwBOAj4CfmNmq8zsJ2Z2TCYLN7MzzWy1ma0zs5tSvF5hZrVmtiR8fK/Fn0SkjaqsDAaH6weI65/nc3xh/PhgUHnXruCvEkJ+5fOU4LRjCu5e7e53uvsQ4FvA+WRwkx0zKwEeBM4C+gHjzKxfiqZPufvg8PFI88IXEWnb8n1KcCYXr7U3s3PNbCbBRWtrgLEZLHs4sM7d33H3L4BZBIPWIq1SIZSIaMlAsbRuU6ZAXd2e8+rqgvlRaGqg+XQzmw7UABOBuUBvd7/E3Z/PYNlHAe8lTdeE8xoaa2bLzGy2mXVvRuwieVUIJSIKITFJfuX7lOCmjhRuBhYCfd39XHef6e6fNWPZlmJew8tmfgeUhjfseRl4LOWCzCaaWZWZVdXW1jYjBBGR1i3fpwQ3NdA80t0fdvePWrjsGiD5l383YEODdWxy97+Hkw8DQxuJZZq7l7t7eZcuXVoYjkjz5fLMH/3Kl5bI9ynBGVdJbYFFQB8z62VmHYBLgTnJDcysa9LkaDIYwBbJp1ye+VMI3U9xyfbsmWIuyJfvU4Kbuh1nVtx9h5lNAl4ESoDp7r7SzG4Dqtx9DnCNmY0mKJvxEVARVTwiEo/6s2fqB0vrz56BzHZs2b6/LRg/Pn+fNW1BvEKjgngSl8rK5h8hVFamPkKYOrV4upOyLaingny5kWlBPCUFkTxpSYXStqBdu9Sf2yy4GC7q90sgl1VSRURaLNuzZ1SQL7+UFETypFgvPMv27BkV5MsvJQWRPCmWMYSGsj17RgX58ktjCiIiRUBjCiIi0mxKCiIikqCkICIiCUoKIiKSoKQgIiIJSgoiIpKgpCAiErHWVOU1siqpIiLS+qq86khBRCSNbH7p5/sey9lSUpCiUaxlJiQ79b/0q6uDaq31v/QzTQz5vsdytpQUpGjozmeto087CnH+0m9tVV6VFERagWx2atn+0m3t4v6l3+qqvLp7q3oMHTrURTI1dWr9XZX3fEydmvkynnjCvWdPd7Pg7xNPRBNrU+vv1GnP+Dt1yjyOnj1Tb4OePaOMunBk+/lzsf3i/g65uxPcBjntPlZVUqVotOTOZw3PHIHgV14+SzdnezvKYr9zWbafvxC+A7mgKqkiOVAIZ45k233R2vq0cy3bz19s93OINCmY2ZlmttrM1pnZTU20u9DM3MzSZjGR5qrvj4fm98cXwpkj2e7UWl2fdo7l4vOPHx8cle3aFfxtqwkBiG5MASgB3gaOBjoAS4F+Kdp1BhYAfwHK0y1XYwrSHIXQH59tf3K2nyEXMbR2xf753TMfU4gyKZwAvJg0/SPgRyna/StwDvCqkoI0pTmDw/Wy3alnu0POxQ69fjnFvlOT7GSaFCIbaDazC4Ez3f174fS3gRHuPimpzRDgFncfa2avAv/s7nuNIpvZRGAiQI8ePYZWpxp1kzavJQPFuRhknTkzGEN4992gy+b22zPvPsh2kFgkVzIdaI6y9pGlmJf472lm7YB7gIp0C3L3acA0CM4+ylF8UgR69Ei9U27OIOv48S3vQy6EMQmR5ohyoLkG6J403Q3YkDTdGRgAvGpm64HjgTkabJZklZXBr3oLf2LUP8+0ZEXcg6zFfuaPtD5RJoVFQB8z62VmHYBLgTn1L7r7J+5+mLuXunspwUDz6FTdR5KduEscZLP+ysrdvfGw+3mmSSHu0wnjTkoizZbJwENLH8DZwBqCs5CmhPNuI9j5N2z7KhENNBfzIF2uBjoLYf2Q+/jyoZi/f1I4iHugOSrNvaK5rVyN2FJxD3TmYv31A73V1cH7mjPQKyIBXdEcKoQrUuPsvol7oDPb9ScXM4PiK+Ymkm9tPinEvVOMu0Jl3AOd2a6/EJK6SDFp80kh7p1i3Du1uAc6s11/3EldpNi0+aQQ904x7p1aLs6+yab7K3n90Pz1x53URYpOJqPRhfRobWcftfZa9nGfPRT32VMibQUZnn3U5o8UIN4Kh3EfqWQr7u6vuK8zECk2RZEU4tTad2rZdn9le0UyFFnZYpGYtfnrFCQ7ubzOoSUF7UQkN3SdguREa+/+EpHmUVJoBeK8+G3t2tRjCmvXNn9ZU6fmJiYRiY66jwpcIZXpUPePSOul7qMcivOXetxn/4hIcSmqpNCcM17qxV2mIu6L35Kp+0ek7Suq7qOWdH+0hSqjIiLqPsqRuH+p6+wfEcmnNp8Usr14Ku7aO6394jcRaV3UfZRGIZ39IyLSUuo+ypG29Eu9JQPtIlJciupIobKyuHeMus5ApHgVxJGCmZ1pZqvNbJ2Z3ZTi9SvMbLmZLTGz18ysX5TxFHNCEBHJRGRJwcxKgAeBs4B+wLgUO/1/d/eB7j4YuAu4O6p4ilUuqpSKSPGI8khhOLDO3d9x9y+AWcCY5AbuviVpcj9AnRs5Vlm5+/Y0sPu5koKIpBJlUjgKeC9puiactwcz+76ZvU1wpHBNhPG0etqRi0jUokwKlmLeXkcC7v6gu/cGbgRuSbkgs4lmVmVmVbW1tTkOs/W49dbs3q8yFSKSTpRJoQbonjTdDdjQRPtZwHmpXnD3ae5e7u7lXbp0yWGIzdPaf6m39vhFJHpRJoVFQB8z62VmHYBLgTnJDcysT9LkN4EWVOnPn2x/qbdkp6yBYhHJp0ivUzCzs4F/BUqA6e5+u5ndBlS5+xwzuxc4DdgOfAxMcveVTS0zzvspZHuef9zvF5HiVRDXKbj7XHc/xt17u/vt4byfuPuc8Plkd+/v7oPdfWS6hBAH/VIXkWKiMhdpZHtKZy6TigaKRSRqRVXmIlvq/hGR1qoguo/aGv1SF5G2TkmhGbIdR1BSEZFCp6SQRxqcFpFCp6QgIiIJSgoiIpJPfBTUAAAGo0lEQVSgpCAiIglKCiIikqCkICIiCa3u4jUzqwWq446jEYcBH8YdRBMUX3YKPT4o/BgVX3ayia+nu6ctM93qkkIhM7OqTK4YjIviy06hxweFH6Piy04+4lP3kYiIJCgpiIhIgpJCbk2LO4A0FF92Cj0+KPwYFV92Io9PYwoiIpKgIwUREUlQUmgmM+tuZq+Y2SozW2lmk1O0OdnMPjGzJeHjJ3mOcb2ZLQ/XvdfNJyxwn5mtM7NlZnZcHmM7Nmm7LDGzLWZ2bYM2ed9+ZjbdzD4wsxVJ8w4xsz+Z2drw78GNvPc7YZu1ZvadPMX2/8zsv8N/v+fM7KBG3tvkdyHiGCvN7G9J/45nN/LeM81sdfh9vCmP8T2VFNt6M1vSyHsj3YaN7VNi+/65ux7NeABdgePC552BNUC/Bm1OBn4fY4zrgcOaeP1s4D8AA44H/hpTnCXA/xKcPx3r9gNOBI4DViTNuwu4KXx+E3BnivcdArwT/j04fH5wHmI7A9gnfH5nqtgy+S5EHGMl8M8ZfAfeBo4GOgBLG/5/iiq+Bq//AvhJHNuwsX1KXN8/HSk0k7tvdPc3wuefAquAo+KNqtnGAI974C/AQWbWNYY4TgXedvfYL0Z09wXARw1mjwEeC58/BpyX4q2jgD+5+0fu/jHwJ+DMqGNz95fcfUc4+RegWy7X2VyNbL9MDAfWufs77v4FMItgu+dUU/GZmQEXA0/mer2ZaGKfEsv3T0khC2ZWCgwB/pri5RPMbKmZ/YeZ9c9rYODAS2a22Mwmpnj9KOC9pOka4klsl9L4f8Q4t1+9I9x9IwT/cYHDU7QphG15GcGRXyrpvgtRmxR2cU1vpPujELbfN4D33X1tI6/nbRs22KfE8v1TUmghM9sfeBa41t23NHj5DYIukUHA/cDzeQ7va+5+HHAW8H0zO7HB65biPXk9Dc3MOgCjgWdSvBz39muOWLelmU0BdgAzG2mS7rsQpYeA3sBgYCNBF01DsX8XgXE0fZSQl22YZp/S6NtSzMtq+ykptICZtSf4x5vp7r9t+Lq7b3H3reHzuUB7MzssX/G5+4bw7wfAcwSH6MlqgO5J092ADfmJLuEs4A13f7/hC3FvvyTv13erhX8/SNEmtm0ZDiqeA4z3sIO5oQy+C5Fx9/fdfae77wIebmTdsX4XzWwf4ALgqcba5GMbNrJPieX7p6TQTGH/46PAKne/u5E2Xw7bYWbDCbbzpjzFt5+Zda5/TjAguaJBsznAP4ZnIR0PfFJ/mJpHjf46i3P7NTAHqD+b4zvACynavAicYWYHh90jZ4TzImVmZwI3AqPdva6RNpl8F6KMMXmc6vxG1r0I6GNmvcKjx0sJtnu+nAb8t7vXpHoxH9uwiX1KPN+/qEbU2+oD+DrB4dkyYEn4OBu4ArgibDMJWElwJsVfgK/mMb6jw/UuDWOYEs5Pjs+ABwnO+lgOlOd5G3Yi2MkfmDQv1u1HkKA2AtsJfn19FzgU+DOwNvx7SNi2HHgk6b2XAevCx4Q8xbaOoC+5/jv4q7DtkcDcpr4Ledx+/xZ+v5YR7OC6NowxnD6b4Iybt6OKMVV84fwZ9d+7pLZ53YZN7FNi+f7pimYREUlQ95GIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIhMxsp+1ZwTVnFTvNrDS5QqdIodon7gBECsjn7j447iBE4qQjBZE0wnr6d5rZf4WP/xPO72lmfw4Lvv3ZzHqE84+w4B4HS8PHV8NFlZjZw2HN/JfMbN+w/TVm9la4nFkxfUwRQElBJNm+DbqPLkl6bYu7DwceAP41nPcAQQnyMoKCdPeF8+8D5ntQ0O84githAfoAD7p7f2AzMDacfxMwJFzOFVF9OJFM6IpmkZCZbXX3/VPMXw+c4u7vhIXL/tfdDzWzDwlKN2wP529098PMrBbo5u5/T1pGKUHd+z7h9I1Ae3f/v2b2R2ArQTXY5z0sBigSBx0piGTGG3neWJtU/p70fCe7x/S+SVCLaiiwOKzcKRILJQWRzFyS9Hdh+Pw/Cap6AowHXguf/xm4EsDMSszsgMYWambtgO7u/grwQ+AgYK+jFZF80S8Skd32tT1v3v5Hd68/LfVLZvZXgh9S48J51wDTzewGoBaYEM6fDEwzs+8SHBFcSVChM5US4AkzO5Cgeu097r45Z59IpJk0piCSRjimUO7uH8Ydi0jU1H0kIiIJOlIQEZEEHSmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgk/H9kwe0LK8lB6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l2_model_val_loss = l2_model_hist.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, original_val_loss, 'b+', label='Original model')\n",
    "plt.plot(epochs, l2_model_val_loss, 'bo', label='L2-regularized model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "- The dropout rate is the fractio of the features that are being zeroed-out; it is usually set between 0.2 and 0.5.\n",
    "Dropout是由Srivastava等人在2014年的一篇论文中提出的一种针对神经网络模型的正则化方法“Dropout: A Simple Way to Prevent Neural Networks from Overfitting”（下载PDF）。\n",
    "\n",
    "Dropout是在训练期间随机选择的一些神经元忽略的技术。他们随机“Dropout”。这意味着它们对下游神经元的激活的贡献暂时消除，并且在反向过程没有实施任何权重的更新。\n",
    "\n",
    "每轮权重更新，以给定的概率(例如20%)从随机选择的节点中舍弃，这个过程很容易实现。这就是在Keras中实现Dropout。Dropout仅在训练模型时使用，在评估模型的技能时不使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0322f7681546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlayer_output\u001b[0m \u001b[1;33m*=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'layer_output' is not defined"
     ]
    }
   ],
   "source": [
    "layer_output *=np.randint(0,high=2,size=layer_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpt_model = models.Sequential()\n",
    "dpt_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(16, activation='relu'))\n",
    "dpt_model.add(layers.Dropout(0.5))\n",
    "dpt_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "dpt_model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 26s 1ms/step - loss: 0.5573 - acc: 0.7182 - val_loss: 0.4038 - val_acc: 0.8624\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 14s 547us/step - loss: 0.3982 - acc: 0.8452 - val_loss: 0.3092 - val_acc: 0.8857\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 8s 326us/step - loss: 0.3272 - acc: 0.8844 - val_loss: 0.2868 - val_acc: 0.8894\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 6s 259us/step - loss: 0.2758 - acc: 0.9056 - val_loss: 0.2796 - val_acc: 0.8877\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 6s 242us/step - loss: 0.2433 - acc: 0.9204 - val_loss: 0.2886 - val_acc: 0.8886\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 6s 243us/step - loss: 0.2189 - acc: 0.9286 - val_loss: 0.3046 - val_acc: 0.8811\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.1951 - acc: 0.9370 - val_loss: 0.3227 - val_acc: 0.8856\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.1791 - acc: 0.9418 - val_loss: 0.3481 - val_acc: 0.8815\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 6s 245us/step - loss: 0.1653 - acc: 0.9459 - val_loss: 0.3566 - val_acc: 0.8806\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 6s 229us/step - loss: 0.1540 - acc: 0.9506 - val_loss: 0.3816 - val_acc: 0.8806\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.1463 - acc: 0.9552 - val_loss: 0.3998 - val_acc: 0.8768\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 6s 224us/step - loss: 0.1383 - acc: 0.9564 - val_loss: 0.4590 - val_acc: 0.8764\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 6s 222us/step - loss: 0.1339 - acc: 0.9588 - val_loss: 0.4407 - val_acc: 0.8735\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 6s 226us/step - loss: 0.1237 - acc: 0.9625 - val_loss: 0.4729 - val_acc: 0.8755\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 6s 227us/step - loss: 0.1242 - acc: 0.9602 - val_loss: 0.5132 - val_acc: 0.8768\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 6s 234us/step - loss: 0.1198 - acc: 0.9625 - val_loss: 0.5182 - val_acc: 0.8744\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 6s 222us/step - loss: 0.1146 - acc: 0.9650 - val_loss: 0.5430 - val_acc: 0.8750\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 6s 236us/step - loss: 0.1137 - acc: 0.9660 - val_loss: 0.5592 - val_acc: 0.8739\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 6s 244us/step - loss: 0.1075 - acc: 0.9680 - val_loss: 0.5619 - val_acc: 0.8710\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 7s 263us/step - loss: 0.1130 - acc: 0.9657 - val_loss: 0.5888 - val_acc: 0.8723\n"
     ]
    }
   ],
   "source": [
    "dpt_model_hist = dpt_model.fit(x_train, y_train,\n",
    "                               epochs=20,\n",
    "                               batch_size=512,\n",
    "                               validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
