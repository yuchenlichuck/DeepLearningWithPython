{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esides Deep Dream, another major development in deep learning-driven image modification that happened in the summer of 2015 is neural style transfer, introduced by Leon Gatys et al. The neural style transfer algorithm has undergone many refinements and spawned many variations since its original introduction, including a viral smartphone app, called Prisma. For simplicity, this section focuses on the formulation described in the original paper.\n",
    "\n",
    "Neural style transfer consists in applying the \"style\" of a reference image to a target image, while conserving the \"content\" of the target image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''loss = distance(style(reference_image) - style(generated_image)) +\n",
    "       distance(content(original_image) - content(generated_image))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where distance is a norm function such as the L2 norm, content is a function that takes an image and computes a representation of its \"content\", and style is a function that takes an image and computes a representation of its \"style\".\n",
    "\n",
    "Minimizing this loss would cause style(generated_image) to be close to style(reference_image), while content(generated_image) would be close to content(generated_image), thus achieving style transfer as we defined it.\n",
    "\n",
    "A fundamental observation made by Gatys et al is that deep convolutional neural networks offer precisely a way to mathematically defined the style and content functions. Let's see how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "\n",
    "target_image_path='E:/photo/avril_cropped.jpg'\n",
    "\n",
    "style_reference_image='E:/photo/impronte_d_artista_cropped.jpg'\n",
    "\n",
    "w,h=load_img(target_image_path).size\n",
    "img_h=400\n",
    "img_w=int(w*img_h/h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_h, img_w))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "target_image=K.constant(preprocess_image(target_image_path))\n",
    "style_reference_image=K.constant((preprocess_image(style_reference_image)))\n",
    "combination_image=K.placeholder((1,img_h,img_w,3))\n",
    "input_tensor =K.concatenate([target_image,style_reference_image,combination_image],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "model = vgg19.VGG19(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(bass,combination):\n",
    "    return K.sum(K.square(combination-bass))\n",
    "def gram_matrix(x):\n",
    "    features=K.batch_flatten(K.permute_dimensions(x,(2,0,1)))\n",
    "    gram=K.dot(features,K.transpose(features))\n",
    "    \n",
    "    return gram\n",
    "\n",
    "def style_loss(style,combination):\n",
    "    S=gram_matrix(style)\n",
    "    C=gram_matrix(combination)\n",
    "    size=img_h*img_w\n",
    "    return K.sum(K.square(S-C))/(4.*(3**2)*(size**2))\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a=K.square(\n",
    "        x[:,:img_h-1,:img_w-1,:]-x[:,1:,:img_w-1,:])\n",
    "    \n",
    "    b=K.square(\n",
    "    x[:,:img_h-1,:img_w-1,:]-x[:,:img_h-1,1:,:])\n",
    "    return K.sum(K.pow(a+b,1.25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "# Name of layer used for content loss\n",
    "content_layer = 'block5_conv2'\n",
    "# Name of layers used for style loss\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "# Weights in the weighted average of the loss components\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "\n",
    "# Define the loss by adding all components to a `loss` variable\n",
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict[content_layer]\n",
    "target_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss += content_weight * content_loss(target_image_features,\n",
    "                                      combination_features)\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(style_layers)) * sl\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)[0]\n",
    "\n",
    "# Function to fetch the values of the current loss and the current gradients\n",
    "fetch_loss_and_grads = K.function([combination_image], [loss, grads])\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_h, img_w, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 3163619800.0\n",
      "Image saved as style_transfer_result_at_iteration_0.png\n",
      "Iteration 0 completed in 89s\n",
      "Start of iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 2279670800.0\n",
      "Image saved as style_transfer_result_at_iteration_1.png\n",
      "Iteration 1 completed in 91s\n",
      "Start of iteration 2\n",
      "Current loss value: 1876965900.0\n",
      "Image saved as style_transfer_result_at_iteration_2.png\n",
      "Iteration 2 completed in 91s\n",
      "Start of iteration 3\n",
      "Current loss value: 1655852300.0\n",
      "Image saved as style_transfer_result_at_iteration_3.png\n",
      "Iteration 3 completed in 92s\n",
      "Start of iteration 4\n",
      "Current loss value: 1518346800.0\n",
      "Image saved as style_transfer_result_at_iteration_4.png\n",
      "Iteration 4 completed in 94s\n",
      "Start of iteration 5\n",
      "Current loss value: 1418753400.0\n",
      "Image saved as style_transfer_result_at_iteration_5.png\n",
      "Iteration 5 completed in 92s\n",
      "Start of iteration 6\n",
      "Current loss value: 1342787200.0\n",
      "Image saved as style_transfer_result_at_iteration_6.png\n",
      "Iteration 6 completed in 91s\n",
      "Start of iteration 7\n",
      "Current loss value: 1286344600.0\n",
      "Image saved as style_transfer_result_at_iteration_7.png\n",
      "Iteration 7 completed in 90s\n",
      "Start of iteration 8\n",
      "Current loss value: 1242535300.0\n",
      "Image saved as style_transfer_result_at_iteration_8.png\n",
      "Iteration 8 completed in 91s\n",
      "Start of iteration 9\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "import time\n",
    "\n",
    "result_prefix = 'style_transfer_result'\n",
    "iterations = 10\n",
    "\n",
    "# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss.\n",
    "# This is our initial state: the target image.\n",
    "# Note that `scipy.optimize.fmin_l_bfgs_b` can only process flat vectors.\n",
    "x = preprocess_image(target_image_path)\n",
    "x = x.flatten()\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x,\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # Save current generated image\n",
    "    img = x.copy().reshape((img_h, img_w, 3))\n",
    "    img = deprocess_image(img)\n",
    "    fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
