{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim=32\n",
    "h=32\n",
    "w=32\n",
    "c=3\n",
    "generator_input=keras.Input(shape=(latent_dim,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=layers.Dense(128*16*16)(generator_input)\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Reshape((16,16,128))(x)\n",
    "x=layers.Conv2D(256,5,padding='same')(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2DTranspose(256,4,strides=2,padding='same')(x)\n",
    "\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2D(256,5,padding='same')(x)\n",
    "\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2D(256,5,padding='same')(x)\n",
    "\n",
    "x=layers.LeakyReLU()(x)\n",
    "\n",
    "x=layers.Conv2D(c,7,activation='tanh',padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator=keras.models.Model(generator_input,x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input=layers.Input(shape=(h,w,c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=layers.Conv2D(128,3)(discriminator_input)\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2D(128,4,strides=2)(x)\n",
    "x=layers.LeakyReLU()(x)\n",
    "\n",
    "x=layers.Conv2D(128,4,strides=2)(x)\n",
    "x=layers.LeakyReLU()(x)\n",
    "\n",
    "x=layers.Conv2D(128,4,strides=2)(x)\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x=layers.Dropout(0.4)(x)\n",
    "x=layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "discriminator=Model(discriminator_input,x)\n",
    "\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer=keras.optimizers.RMSprop(lr=0.0008,clipvalue=1.0,decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable=False\n",
    "\n",
    "gan_input=keras.Input(shape=(latent_dim,))\n",
    "gan_output=discriminator(generator(gan_input))\n",
    "gan=Model(gan_input,gan_output)\n",
    "from keras.optimizers import RMSprop\n",
    "gan_optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8)\n",
    "\n",
    "gan.compile(optimizer=gan_optimizer,loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start training. To recapitulate, this is schematically what the training loop looks like:\n",
    "\n",
    "for each epoch:\n",
    "    * Draw random points in the latent space (random noise).\n",
    "    * Generate images with `generator` using this random noise.\n",
    "    * Mix the generated images with real ones.\n",
    "    * Train `discriminator` using these mixed images, with corresponding targets, either \"real\" (for the real images) or \"fake\" (for the generated images).\n",
    "    * Draw new random points in the latent space.\n",
    "    * Train `gan` using these random vectors, with targets that all say \"these are real images\". This will update the weights of the generator (only, since discriminator is frozen inside `gan`) to move them towards getting the discriminator to predict \"these are real images\" for generated images, i.e. this trains the generator to fool the discriminator.\n",
    "Let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "155541504/170498071 [==========================>...] - ETA: 26s"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "(x_train,y_train),(_,_)=keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train=x_train[y_train.flatten()==6]\n",
    "\n",
    "x_train=x_train.reshape(\n",
    "    \n",
    "    (x_train.shape[0],)+(h,w,c)).astype('float32')/255.\n",
    "\n",
    "iter=10000\n",
    "batch_size=20\n",
    "save_dir='./gan_images/'\n",
    "for step in range(iter):\n",
    "    random_latent_vectors=np.random.normal(size=(batch_size,latent_dim))\n",
    "    \n",
    "    generated_images=generator.predict(random_latent_vectors)\n",
    "    \n",
    "    stop=start+batch_size\n",
    "    read_image=x_train[start:stop]\n",
    "    combined_images=np.concatenate([generated_images],real_images)\n",
    "    \n",
    "    labels=np.concatenate([np.ones((batch_size,1)),\n",
    "                          np.zeros((batch_size,1))])\n",
    "    \n",
    "    labels+=0.05*np.random.random(labels.shape)\n",
    "    d_loss=discriminator.train_on_batch(combined_images,labels)\n",
    "    \n",
    "    random_latent_vectors=np.random.normal(size=(batch_size,latent_dim))\n",
    "    misleading_targets=np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss=gan.train_on_batch(random_latent_vectors,misleading_targets)\n",
    "    \n",
    "    start+=batch_size\n",
    "    \n",
    "    if start>len(x_train)-batch_size:\n",
    "        start=0\n",
    "        \n",
    "    if step%100==0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "          print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
