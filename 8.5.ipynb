{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim=32\n",
    "h=32\n",
    "w=32\n",
    "c=3\n",
    "generator_input=keras.Input(shape=(latent_dim,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=layers.Dense(128*16*16)(generator_input)\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Reshape((16,16,128))(x)\n",
    "x=layers.Conv2D(256,5,padding='same')(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2DTranspose(256,4,strides=2,padding='same')(x)\n",
    "\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2D(256,5,padding='same')(x)\n",
    "\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2D(256,5,padding='same')(x)\n",
    "\n",
    "x=layers.LeakyReLU()(x)\n",
    "\n",
    "x=layers.Conv2D(c,7,activation='tanh',padding='same')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator=keras.models.Model(generator_input,x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input=layers.Input(shape=(h,w,c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=layers.Conv2D(128,3)(discriminator_input)\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Conv2D(128,4,strides=2)(x)\n",
    "x=layers.LeakyReLU()(x)\n",
    "\n",
    "x=layers.Conv2D(128,4,strides=2)(x)\n",
    "x=layers.LeakyReLU()(x)\n",
    "\n",
    "x=layers.Conv2D(128,4,strides=2)(x)\n",
    "x=layers.LeakyReLU()(x)\n",
    "x=layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x=layers.Dropout(0.4)(x)\n",
    "x=layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "discriminator=Model(discriminator_input,x)\n",
    "\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer=keras.optimizers.RMSprop(lr=0.0008,clipvalue=1.0,decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable=False\n",
    "\n",
    "gan_input=keras.Input(shape=(latent_dim,))\n",
    "gan_output=discriminator(generator(gan_input))\n",
    "gan=Model(gan_input,gan_output)\n",
    "from keras.optimizers import RMSprop\n",
    "gan_optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8)\n",
    "\n",
    "gan.compile(optimizer=gan_optimizer,loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start training. To recapitulate, this is schematically what the training loop looks like:\n",
    "\n",
    "for each epoch:\n",
    "    * Draw random points in the latent space (random noise).\n",
    "    * Generate images with `generator` using this random noise.\n",
    "    * Mix the generated images with real ones.\n",
    "    * Train `discriminator` using these mixed images, with corresponding targets, either \"real\" (for the real images) or \"fake\" (for the generated images).\n",
    "    * Draw new random points in the latent space.\n",
    "    * Train `gan` using these random vectors, with targets that all say \"these are real images\". This will update the weights of the generator (only, since discriminator is frozen inside `gan`) to move them towards getting the discriminator to predict \"these are real images\" for generated images, i.e. this trains the generator to fool the discriminator.\n",
    "Let's implement it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 0: 2.90828\n",
      "adversarial loss at step 0: 15.810432\n",
      "discriminator loss at step 100: 0.63443935\n",
      "adversarial loss at step 100: 1.0343671\n",
      "discriminator loss at step 200: 0.71812767\n",
      "adversarial loss at step 200: 0.69485116\n",
      "discriminator loss at step 300: 0.71559393\n",
      "adversarial loss at step 300: 0.7613785\n",
      "discriminator loss at step 400: 0.69547176\n",
      "adversarial loss at step 400: 0.7444247\n",
      "discriminator loss at step 500: 0.6910823\n",
      "adversarial loss at step 500: 0.7347973\n",
      "discriminator loss at step 600: 0.70495445\n",
      "adversarial loss at step 600: 0.7769234\n",
      "discriminator loss at step 700: 0.68687665\n",
      "adversarial loss at step 700: 0.75351006\n",
      "discriminator loss at step 800: 0.7004467\n",
      "adversarial loss at step 800: 0.6925286\n",
      "discriminator loss at step 900: 0.7083837\n",
      "adversarial loss at step 900: 0.7518848\n",
      "discriminator loss at step 1000: 0.691304\n",
      "adversarial loss at step 1000: 0.80026805\n",
      "discriminator loss at step 1100: 0.6881939\n",
      "adversarial loss at step 1100: 0.7618004\n",
      "discriminator loss at step 1200: 0.6892893\n",
      "adversarial loss at step 1200: 0.72659665\n",
      "discriminator loss at step 1300: 0.68126243\n",
      "adversarial loss at step 1300: 0.7894167\n",
      "discriminator loss at step 1400: 0.6924275\n",
      "adversarial loss at step 1400: 0.7279865\n",
      "discriminator loss at step 1500: 0.6813438\n",
      "adversarial loss at step 1500: 0.79753196\n",
      "discriminator loss at step 1600: 0.7003714\n",
      "adversarial loss at step 1600: 0.798625\n",
      "discriminator loss at step 1700: 0.67974627\n",
      "adversarial loss at step 1700: 0.7096987\n",
      "discriminator loss at step 1800: 0.704171\n",
      "adversarial loss at step 1800: 0.7581285\n",
      "discriminator loss at step 1900: 0.70780903\n",
      "adversarial loss at step 1900: 0.7264922\n",
      "discriminator loss at step 2000: 0.82357705\n",
      "adversarial loss at step 2000: 0.74453586\n",
      "discriminator loss at step 2100: 0.7113414\n",
      "adversarial loss at step 2100: 0.81035995\n",
      "discriminator loss at step 2200: 0.6910742\n",
      "adversarial loss at step 2200: 0.7367593\n",
      "discriminator loss at step 2300: 0.69090915\n",
      "adversarial loss at step 2300: 0.7311122\n",
      "discriminator loss at step 2400: 0.7010461\n",
      "adversarial loss at step 2400: 0.7403373\n",
      "discriminator loss at step 2500: 0.68992573\n",
      "adversarial loss at step 2500: 0.7710865\n",
      "discriminator loss at step 2600: 0.6763656\n",
      "adversarial loss at step 2600: 0.703477\n",
      "discriminator loss at step 2700: 0.6929897\n",
      "adversarial loss at step 2700: 0.7559808\n",
      "discriminator loss at step 2800: 0.69683754\n",
      "adversarial loss at step 2800: 0.7336262\n",
      "discriminator loss at step 2900: 0.7094229\n",
      "adversarial loss at step 2900: 0.761591\n",
      "discriminator loss at step 3000: 0.70985615\n",
      "adversarial loss at step 3000: 0.75288266\n",
      "discriminator loss at step 3100: 0.7491969\n",
      "adversarial loss at step 3100: 0.7056757\n",
      "discriminator loss at step 3200: 0.69897205\n",
      "adversarial loss at step 3200: 0.77546304\n",
      "discriminator loss at step 3300: 0.6981267\n",
      "adversarial loss at step 3300: 0.7606363\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-54fdf52d3df9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmisleading_targets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0ma_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmisleading_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mstart\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "(x_train,y_train),(_,_)=keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train=x_train[y_train.flatten()==6]\n",
    "\n",
    "x_train=x_train.reshape(\n",
    "    \n",
    "    (x_train.shape[0],)+(h,w,c)).astype('float32')/255.\n",
    "\n",
    "iter=10000\n",
    "batch_size=20\n",
    "save_dir='./gan_images/'\n",
    "os.mkdir(save_dir)\n",
    "start=0\n",
    "for step in range(iter):\n",
    "    random_latent_vectors=np.random.normal(size=(batch_size,latent_dim))\n",
    "    \n",
    "    generated_images=generator.predict(random_latent_vectors)\n",
    "    \n",
    "    stop=start+batch_size\n",
    "    real_images=x_train[start:stop]\n",
    "    combined_images=np.concatenate([generated_images,real_images])\n",
    "    \n",
    "    labels=np.concatenate([np.ones((batch_size,1)),\n",
    "                          np.zeros((batch_size,1))])\n",
    "    \n",
    "    labels+=0.05*np.random.random(labels.shape)\n",
    "    d_loss=discriminator.train_on_batch(combined_images,labels)\n",
    "    \n",
    "    random_latent_vectors=np.random.normal(size=(batch_size,latent_dim))\n",
    "    misleading_targets=np.zeros((batch_size,1))\n",
    "    \n",
    "    a_loss=gan.train_on_batch(random_latent_vectors,misleading_targets)\n",
    "    \n",
    "    start+=batch_size\n",
    "    \n",
    "    if start>len(x_train)-batch_size:\n",
    "        start=0\n",
    "        \n",
    "    if step%100==0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
    "\n",
    "        img=image.array_to_img(generated_images[0]*255,scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog'+str(step)+'.png'))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample random points in the latent space\n",
    "random_latent_vectors = np.random.normal(size=(10, latent_dim))\n",
    "\n",
    "# Decode them to fake images\n",
    "generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "for i in range(generated_images.shape[0]):\n",
    "    img = image.array_to_img(generated_images[i] * 255., scale=False)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
